# used in backup_filename
name = 'laptop'
# influx:: host TAG
host = 'spongebob'
work_dir = '/home/conan/soft/rust/metynka'


[flag]
debug_new_config = false

debug_ts = false
# future_use
debug_ts_to_dt = false

# view metric Struct parsed config data
debug_metric_instances = false
# RAW_JSON
debug_sensor_output = false
# JSON value
debug_pointer_output = false 
# record Struct
debug_metric_record = false

# view influx Struct parsed config data
debug_influx_instances = false
debug_influx_lp = false
debug_influx_uri = true # false
debug_influx_auth = false
# CURL stdout/stderr
debug_influx_output = false

# query influx to verify write was successfull
run_flux_verify_record = true # false
# add |> count() to [template.flux].query_verify_record
add_flux_query_verify_record_suffix = false

debug_flux_query = false
debug_flux_result = false

# search for QUERY in this CONFIG_FILE
run_egrep = false
debug_egrep = true # false

# display CSV ANNOTATED data to backup
debug_backup = true # false


#hash map
[metrics]
[metrics.temperature]
flag_status = true # false
# influx:: measurement
measurement = "temperature"

program = "/usr/bin/sensors"
args = ["-j"]

flag_pipe = false
pipe_program = ""
pipe_args = []

#status: on/off
#name: influx:: SensorId TAG -> if changed will impact flux query
#pointer: json path
#
# DO NOT BREAK LINES IN Struct AS IT WILL !panic
values = [
       {status=true, name="0", pointer="/coretemp-isa-0000/Core 0/temp2_input"},
       {status=true, name="1", pointer="/coretemp-isa-0000/Core 1/temp3_input"},
       {status=true, name="2", pointer="/acpitz-acpi-0/temp2/temp2_input"},
       {status=true, name="3", pointer="/acpitz-acpi-0/temp1/temp1_input"},
       ]

# influx:: TAG names
tag_machine = "Machine"
tag_id = "SensorId"
tag_carrier = "SensorCarrier" 
tag_valid = "SensorValid"
# influx:: _field
field = "TemperatureDecimal"

annotated_datatype = "#datatype measurement,tag,tag,tag,tag,tag,double,dateTime:number"
annotated_header = "m,host,{tag_machine},{tag_id},{tag_carrier},{tag_valid},{field},time"
csv_annotated = '{measurement},{host},{machine},{id},{carrier},{valid},{value},{ts}'
generic_lp = "{measurement},host={host},{tag_machine}={machine_id},{tag_id}={id},{tag_carrier}={carrier},{tag_valid}={valid} {field}={value} {ts}"
generic_query_verify_record = "from(bucket: \"{bucket}\") |> range(start: {start}) |> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\") |> filter(fn: (r) => r[\"{tag_id}\"] == \"{id}\") |> filter(fn: (r) => r[\"_time\"] == {dtif}) |> sort(columns: [\"_time\"], desc:true) |> drop(columns:[\"_start\", \"_stop\", \"host\", \"_measurement\",\"{tag_carrier}\", \"{tag_valid}\", \"_field\"]) |> limit(n:1) |> group()"


[metrics.memory]
flag_status = true # false
# influx:: measurement
measurement = "memory_float"

program = "/bin/cat"
args = ["/proc/meminfo"]

flag_pipe = true # false
pipe_program = "jq"
pipe_args = [
	  "--slurp",
	  "--raw-input",
	  "split(\"\n\") | map(select(. != \"\") | split(\":\") | {\"key\": .[0], \"value\": (.[1:]| map_values(.[0:-3]) | join(\"\") | split(\" \") | .[1:] | join(\"\"))}) | from_entries"]

#status: on/off
#name: influx:: SensorId TAG -> if changed will impact flux query
#pointer: json path
#
# DO NOT BREAK LINES IN Struct AS IT WILL !panic
values = [
       {status=true, name="memory_free", pointer="/MemFree"},
       {status=true, name="memory_available", pointer="/MemAvailable"}, #e
       ]

# influx:: TAG names
tag_machine = "Machine"
tag_id = "MemoryId"
tag_carrier = "MemoryCarrier" 
tag_valid = "MemoryValid"
# influx:: _field
field = "MemoryDecimal"

annotated_datatype = "#datatype measurement,tag,tag,tag,tag,tag,double,dateTime:number"
annotated_header = "m,host,{tag_machine},{tag_id},{tag_carrier},{tag_valid},{field},time"
csv_annotated = '{measurement},{host},{machine},{id},{carrier},{valid},{value},{ts}'
generic_lp = "{measurement},host={host},{tag_machine}={machine_id},{tag_id}={id},{tag_carrier}={carrier},{tag_valid}={valid} {field}={value} {ts}"
generic_query_verify_record = "from(bucket: \"{bucket}\") |> range(start: {start}) |> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\") |> filter(fn: (r) => r[\"{tag_id}\"] == \"{id}\") |> filter(fn: (r) => r[\"_time\"] == {dtif}) |> sort(columns: [\"_time\"], desc:true) |> drop(columns:[\"_start\", \"_stop\", \"host\", \"_measurement\",\"{tag_carrier}\", \"{tag_valid}\", \"_field\"]) |> limit(n:1) |> group()"


# future_use
[delay]
second = 60
minute = 1


# backup always, no flag to turn off
[backup]
dir = "csv"
file_extension = "csv"


# vector of influx: Struct instances
[all_influx]
#name: "default"		-> instance_id
#status: true			-> on/off

#secure: 			-> http/https 
#server: "ruth"			-> ip or hostname
#port: 8086

#bucket: "test_rust"		-> DO NOT FORGET TO CREATE
#token	 			-> TOKEN
#org: "foookin_paavel"
#precision: "ms"		-> 1636918801582 / MS format len() 13

#TAGS
#machine_id: "spongebob"	-> now same as host but normaly another machine like T4_labjack / esp32 / ...
#carrier: "cargo" 	     	-> future_use
#flag_valid_default:  true	-> for flux filtering invalid data before delete

# DO NOT BREAK LINES IN Struct AS IT WILL !panic
values = [
       {name = "default", status = true, secure = "https", server = "ruth", port = 8086, bucket = "test_rust", token = "riMIsymqgtxF6vGnTfhpSCWPcijRRQ2ekwbS5H8BkPXHr_HtCNUqKLwOnyHpMjQB-L6ZscVFo8PsGbGgoxEFLw==", org = "foookin_paavel", precision = "ms", machine_id = "spongebob", carrier = "cargo", flag_valid_default = true},
       {name = "backup", status = true, secure = "http", server = "jozefina", port = 8086, bucket = "backup_test_rust", token = "jbD0MXwVzetW6r6TFSQ5xIAzSFxwl3rD8tJVvzWr_Ax7ZNBJH1A0LHu38PR8WFWEpy0SuDlYpMyjYBB52riFrA==", org = "foookin_paavel", precision = "ms", machine_id = "spongebob", carrier = "cargo", flag_valid_default = true},
       ]


[template]
# influx params
[template.curl]
program = "/usr/bin/curl"
param_insecure = "--insecure"
param_request = "--request"
param_post = "POST"
param_header = "--header"
param_data = "--data-raw"

influx_uri_api = "{secure}://{server}:{port}/api/v2/"
influx_uri_write = "write?org={org}&bucket={bucket}&precision={precision}"
influx_uri_query = "query?org={org}"

influx_auth = "Authorization: Token {token}"
influx_accept = "Accept: application/csv"
influx_content = "Content-type: application/vnd.flux"



[template.flux]
# verification duration range
query_verify_record_range_start = "-1h"
query_verify_record_suffix = " |> count()"
#
# INFLUX API query CALL via CURL
#
#$ /usr/bin/curl --insecure --request POST https://ruth:8086/api/v2/query?org=foookin_paavel --header 'Authorization: Token riMIsymqgtxF6vGnTfhpSCWPcijRRQ2ekwbS5H8BkPXHr_HtCNUqKLwOnyHpMjQB-L6ZscVFo8PsGbGgoxEFLw==' --header 'Accept: application/csv' --header 'Content-type: application/vnd.flux' --data 'from(bucket: "test_rust") |> range(start: -7d) |> filter(fn: (r) => r["_measurement"] == "temperature") |> filter(fn: (r) => r["SensorId"] == "0") |> filter(fn: (r) => r["_value"] == 54.0) |> filter(fn: (r) => r["_time"] == 2021-11-16T11:43:43.871Z) |> sort(columns: ["_time"], desc:true) |> drop(columns:["_start", "_stop", "host", "_measurement","SensorCarrier","SensorValid", "_field"]) |> limit(n:1)'
#
# RESULT
#
#,result,table,_time,_value,Machine,SensorId
#,_result,0,2021-11-16T11:43:43.871Z,54,spongebob,0
#
# $ /usr/bin/curl --insecure --request POST https://ruth:8086/api/v2/query?org=foookin_paavel --header 'Authorization: Token riMIsymqgtxF6vGnTfhpSCWPcijRRQ2ekwbS5H8BkPXHr_HtCNUqKLwOnyHpMjQB-L6ZscVFo8PsGbGgoxEFLw==' --header 'Accept: application/csv' --header 'Content-type: application/vnd.flux' --data 'from(bucket: "test_rust") |> range(start: -6h) |> filter(fn: (r) => r["_measurement"] == "temperature") |> filter(fn: (r) => r["SensorId"] == "0") |> filter(fn: (r) => r["_value"] == 54.0) |> filter(fn: (r) => r["_time"] == 2021-11-16T11:43:43.871Z) |> sort(columns: ["_time"], desc:true) |> drop(columns:["_start", "_stop", "host", "_measurement","SensorCarrier", "SensorValid", "_field"]) |> limit(n:1) |> group()'
#
# RESULT |> group()
#
#,result,table,_time,_value,Machine,SensorId
#,_result,0,2021-11-16T11:43:43.871Z,54,spongebob,0
#
# RESULT |> count()
#
# $ /usr/bin/curl --insecure --request POST https://ruth:8086/api/v2/query?org=foookin_paavel --header 'Authorization: Token riMIsymqgtxF6vGnTfhpSCWPcijRRQ2ekwbS5H8BkPXHr_HtCNUqKLwOnyHpMjQB-L6ZscVFo8PsGbGgoxEFLw==' --header 'Accept: application/csv' --header 'Content-type: application/vnd.flux' --data 'from(bucket: "test_rust") |> range(start: -6h) |> filter(fn: (r) => r["_measurement"] == "temperature") |> filter(fn: (r) => r["SensorId"] == "0") |> filter(fn: (r) => r["_value"] == 54.0) |> filter(fn: (r) => r["_time"] == 2021-11-16T11:43:43.871Z) |> sort(columns: ["_time"], desc:true) |> drop(columns:["_start", "_stop", "host", "_measurement","SensorCarrier", "SensorValid", "_field"]) |> limit(n:1) |> group() |> count()'
#
#,result,table,_value
#,_result,0,1


#[template.temperature]
#flag_status = true # false
#measurement = "temperature"

# $dpkg -l|egrep lm-sensors
# ii  lm-sensors                            1:3.6.0-7                              amd64        utilities to read temperature/voltage/fan sensors
#program = "/usr/bin/sensors"
#args = ["-j"]

#pipe_program = ""
#pipe_args = []

#values = []

# TAG name
#tag_machine = "Machine"
#tag_id = "SensorId"
#tag_carrier = "SensorCarrier" 
#tag_valid = "SensorValid"
#field = "TemperatureDecimal"

# for now only FIX count of TAG's and SINGLE _FIELD
#annotated_datatype = "#datatype measurement,tag,tag,tag,tag,tag,double,dateTime:number"
#annotated_header = "m,host,{tag_machine},{tag_id},{tag_carrier},{tag_valid},{field},time"
#csv_annotated = '{measurement},{host},{machine},{id},{carrier},{valid},{value},{ts}'
#generic_lp = "{measurement},host={host},{tag_machine}={machine_id},{tag_id}={id},{tag_carrier}={carrier},{tag_valid}={valid} {field}={value} {ts}"
#generic_query_verify_record = "from(bucket: \"{bucket}\") |> range(start: {start}) |> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\") |> filter(fn: (r) => r[\"{tag_id}\"] == \"{id}\") |> filter(fn: (r) => r[\"_time\"] == {dtif}) |> sort(columns: [\"_time\"], desc:true) |> drop(columns:[\"_start\", \"_stop\", \"host\", \"_measurement\",\"{tag_carrier}\", \"{tag_valid}\", \"_field\"]) |> limit(n:1) |> group()"


#[template.memory]
#flag_status = false
#measurement = "memory"

#program = "/bin/cat"
#args = ["/proc/meminfo"]

# $ dpkg -l |egrep jq
# ii  jq                                    1.6-2.1                                amd64        lightweight and flexible command-line JSON processor
#pipe_program = "jq"
#pipe_args = [
#	  "--slurp",
#	  "--raw-input",
#	  "split(\"\n\") | map(select(. != \"\") | split(\":\") | {\"key\": .[0], \"value\": (.[1:]| map_values(.[0:-3]) | join(\"\") | split(\" \") | .[1:] | join(\"\#"))}) | from_entries"]

#values = []

# TAG name
#tag_machine = "Machine"
#tag_id = "MemoryId"
#tag_carrier = "MemoryCarrier" 
#tag_valid = "MemoryValid"
#field = "MemoryDecimal"

#annotated_datatype = "#datatype measurement,tag,tag,tag,tag,tag,double,dateTime:number"
#annotated_header = "m,host,{tag_machine},{tag_id},{tag_carrier},{tag_valid},{field},time"
#csv_annotated = '{measurement},{host},{machine},{id},{carrier},{valid},{value},{ts}'
#generic_lp = "{measurement},host={host},{tag_machine}={machine_id},{tag_id}={id},{tag_carrier}={carrier},{tag_valid}={valid} {field}={value} {ts}"
#generic_query_verify_record = "from(bucket: \"{bucket}\") |> range(start: {start}) |> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\") |> filter(fn: (r) => r[\"{tag_id}\"] == \"{id}\") |> filter(fn: (r) => r[\"_time\"] == {dtif}) |> sort(columns: [\"_time\"], desc:true) |> drop(columns:[\"_start\", \"_stop\", \"host\", \"_measurement\",\"{tag_carrier}\", \"{tag_valid}\", \"_field\"]) |> limit(n:1) |> group()"


# IMPORT_from_backup -> EXPORT -> compare/verify
#
# spongebob$ scp -P 11472 /home/conan/soft/rust/ts/csv/2021_11_17_laptop_core_temperature.csv conan@ruth:/home/conan/soft/docker/dck_influxdb_2_0/dck_influxdb_volume/rust/
#
# ruth$ head -n5 /home/conan/soft/docker/dck_influxdb_2_0/dck_influxdb_volume/rust/2021_11_17_laptop_core_temperature.csv 
# #datatype measurement,tag,tag,tag,tag,tag,double,dateTime:number
# m,host,Machine,SensorId,SensorCarrier,SensorValid,TemperatureDecimal,time
# temperature,spongebob,spongebob,0,cargo,true,75.0,1637135171004
# temperature,spongebob,spongebob,1,cargo,true,69.0,1637135171004
# temperature,spongebob,spongebob,2,cargo,true,51.0,1637135171004
#
# ruth$ docker container exec -i -t dck_influxdb influx write --bucket import_test_rust --precision ms --format csv --file /var/lib/influxdb2/rust/2021_11_17_laptop_core_temperature.csv --skip-verify
#
# ruth$ docker container exec -i -t dck_influxdb influx query 'from(bucket:"import_test_rust") |> range(start:-1y) |> drop(columns:["_start", "_stop"])' --raw --skip-verify | head -n 10
#
# #group,false,false,false,false,true,true,true,true,true,true,true
# #datatype,string,long,dateTime:RFC3339,double,string,string,string,string,string,string,string
# #default,_result,,,,,,,,,,
# ,result,table,_time,_value,Machine,SensorCarrier,SensorId,SensorValid,_field,_measurement,host
# ,,0,2021-11-17T07:46:11.004Z,75,spongebob,cargo,0,true,TemperatureDecimal,temperature,spongebob
# ,,0,2021-11-17T07:46:14.094Z,73,spongebob,cargo,0,true,TemperatureDecimal,temperature,spongebob
# ,,0,2021-11-17T07:47:16.864Z,73,spongebob,cargo,0,true,TemperatureDecimal,temperature,spongebob
# ,,0,2021-11-17T07:50:02.449Z,74,spongebob,cargo,0,true,TemperatureDecimal,temperature,spongebob
# ,,0,2021-11-17T07:51:32.246Z,75,spongebob,cargo,0,true,TemperatureDecimal,temperature,spongebob
#,,0,2021-11-17T07:52:12.813Z,74,spongebob,cargo,0,true,TemperatureDecimal,temperature,spongebob
#
# CSV data CAN NOT BE WRITTEN via API -> only LINE_PROTOCOL format
#
# https://docs.influxdata.com/influxdb/v2.1/write-data/developer-tools/api/
#
# SINGLE_RECORD
# $ curl --insecure --request POST "https://ruth:8086/api/v2/write?org=foookin_paavel&bucket=import_test_rust&precision=ms" --header "Authorization: Token riMIsymqgtxF6vGnTfhpSCWPcijRRQ2ekwbS5H8BkPXHr_HtCNUqKLwOnyHpMjQB-L6ZscVFo8PsGbGgoxEFLw==" --header "Content-Type: text/plain; charset=utf-8" --header "Accept: application/json" --data-binary 'temperature,host=spongebob,Machine=spongebob,SensorId=0,SensorCarrier=cargo,SensorValid=true TemperatureDecimal=61.0 1637082830396'
#
# MULTIPLE RECORDS -> --data-binary $'' and \n
# $ curl --insecure --request POST "https://ruth:8086/api/v2/write?org=foookin_paavel&bucket=import_test_rust&precision=ms" --header "Authorization: Token riMIsymqgtxF6vGnTfhpSCWPcijRRQ2ekwbS5H8BkPXHr_HtCNUqKLwOnyHpMjQB-L6ZscVFo8PsGbGgoxEFLw==" --header "Content-Type: text/plain; charset=utf-8" --header "Accept: application/json" --data-binary $'temperature,host=spongebob,Machine=spongebob,SensorId=2,SensorCarrier=cargo,SensorValid=true TemperatureDecimal=48.0 1637083201622\ntemperature,host=spongebob,Machine=spongebob,SensorId=3,SensorCarrier=cargo,SensorValid=true TemperatureDecimal=55.0 1637083201622'
#
# QUERY
# from(bucket: "import_test_rust") |> range(start: -24h) |> filter(fn: (r) => r["_measurement"] == "temperature") |> drop(columns:["_start", "_stop", "host", "_measurement"]) |> sort(columns: ["_time"], desc:true) |> limit(n:20)
#


# vector of sensor: Struct instances
#[all_sensors]
#group: temperature/memory
#status: on/off
#name: influx SensorId TAG
#pointer: json path / influx TemperatureDecimal FIELD
# DO NOT BREAK LINES IN Struct AS IT WILL !panic

#values = [
#       {status=true, name="0", pointer="/coretemp-isa-0000/Core 0/temp2_input"},
#       {status=true, name="1", pointer="/coretemp-isa-0000/Core 1/temp3_input"},
#       {status=true, name="2", pointer="/acpitz-acpi-0/temp2/temp2_input"},
#       {status=true, name="3", pointer="/acpitz-acpi-0/temp1/temp1_input"},
#]

#[template.sensors]
#[template.temperature] ADD TO OLD [template.csv]
# $dpkg -l|egrep lm-sensors
# ii  lm-sensors                            1:3.6.0-7                              amd64        utilities to read temperature/voltage/fan sensors
#program = "/usr/bin/sensors"
#param_1 = "-j"
#args = ["-j"]




# 
#
# https://stedolan.github.io/jq/manual/
#
# https://serverfault.com/questions/907857/how-get-systemd-status-in-json-format
#
# https://manpages.ubuntu.com/manpages/focal/man1/jq.1.html
#
# $ cat /proc/meminfo | jq --slurp --raw-input 'split("\n") | map(select(. != "") | split(":") | {"key": .[0], "value": (.[1:]| map_values(.[0:-3]) | join("") | split(" ") | .[1:] | join(""))}) | from_entries'
#
# {
#  "MemTotal": "7865456",
#  "MemFree": "193284",
#  "MemAvailable": "1829704",
#  "Buffers": "229724",

#[toys]
#[toys.car]
#measurement = "m_car"
#[toys.excavator]
#measurement = "m_excavator"
#[toys.dozer]
#measurement = "m_dozer"
